{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWd7EdNyVBUD5e5Nnhn4fZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anakayam45/dataset_gunting_batu_kertas/blob/main/Klasifikasi_Gambar_Gunting_Batu_Kertas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ZkjuAaXQzrh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import os, matplotlib.pyplot as plt, seaborn as sns, numpy as np, cv2, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/anakayam45/dataset_gunting_batu_kertas.git\"\n",
        "path_to_repo = '/content/dataset_gunting_batu_kertas'"
      ],
      "metadata": {
        "id": "v6o5IatWRun6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = os.path.join(path_to_repo, \"result\")\n",
        "df = tf.keras.utils.image_dataset_from_directory(path_to_dataset, image_size=(128, 128), batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "D8LcC1i-elHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in df.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(int(labels[i]))\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JqdQviJWg_Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "!apt install albumentations\n",
        "from albumentations import RandomBrightnessContrast, GaussianBlur, HorizontalFlip\n",
        "from albumentations.core.composition import Compose, OneOf\n",
        "\n",
        "\n",
        "for folder in (os.listdir(path_to_dataset)):\n",
        "  folder_path = os.path.join(path_to_dataset, folder)\n",
        "  for file in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    if not os.path.isdir(file_path):\n",
        "\n",
        "      flip = A.Compose([A.HorizontalFlip(p=1)])\n",
        "      light = A.Compose([RandomBrightnessContrast(limit=(0.2, 0), p=1)])\n",
        "      dark = A.Compose([RandomBrightnessContrast(limit=(-0.2, 0), p=1)])\n",
        "      blurr = A.Compose([GaussianBlur(p=1)])\n",
        "\n",
        "      if os.path.isfile(file_path):\n",
        "        image = cv2.imread(file_path)\n",
        "\n",
        "        augmented = flip(image=image)\n",
        "        augmented_image = augmented['image']\n",
        "        cv2.imwrite(os.path.join(folder_path, f\"{len(os.listdir(folder_path))+1}_flip.jpg\"), augmented_image)\n",
        "\n",
        "        augmented = light(image=image)\n",
        "        augmented_image = augmented['image']\n",
        "        cv2.imwrite(os.path.join(folder_path, f\"{len(os.listdir(folder_path))+1}_light.jpg\"), augmented_image)\n",
        "\n",
        "        augmented = dark(image=image)\n",
        "        augmented_image = augmented['image']\n",
        "        cv2.imwrite(os.path.join(folder_path, f\"{len(os.listdir(folder_path))+1}_dark.jpg\"), augmented_image)\n",
        "\n",
        "        augmented = blurr(image=image)\n",
        "        augmented_image = augmented['image']\n",
        "        cv2.imwrite(os.path.join(folder_path, f\"{len(os.listdir(folder_path))+1}_blurr.jpg\"), augmented_image)\n"
      ],
      "metadata": {
        "id": "kKJk3T-_iEnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = os.path.join(path_to_repo, \"result\")\n",
        "df = tf.keras.utils.image_dataset_from_directory(path_to_dataset, image_size=(128, 128), batch_size=32, shuffle=True)\n",
        "len(os.listdir(os.path.join(path_to_dataset, \"gunting\")))"
      ],
      "metadata": {
        "id": "nW2S1jANjm2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in df.take(2):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  for i in range(3):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(int(labels[i]))\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mP2pxcvYpdES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pembagian data\n",
        "train_size = 0.8\n",
        "val_size = 0.1\n",
        "test_size = 0.1\n",
        "\n",
        "# Hitung jumlah batch\n",
        "total_batches = len(df)\n",
        "train_batches = int(total_batches * train_size)\n",
        "val_batches = int(total_batches * val_size)\n",
        "\n",
        "# Pembagian dataset\n",
        "train_ds = df.take(train_batches)\n",
        "val_ds = df.skip(train_batches).take(val_batches)\n",
        "test_ds = df.skip(train_batches + val_batches)"
      ],
      "metadata": {
        "id": "9gjn-W8e5MOm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(df.class_names), activation='softmax')  # Sesuaikan jumlah kategori\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "cJ_LmPbe5v4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "DJlJDi_zkNSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    if image is None:\n",
        "        return \"No image uploaded\"\n",
        "    image = image.resize((128, 128))\n",
        "    image = np.array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    predict = model.predict(image)\n",
        "    predicted_class_index = np.argmax(predict)\n",
        "    predicted_class_name = df.class_names[predicted_class_index]\n",
        "    return predicted_class_name\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn = process_image,\n",
        "    inputs = gr.Image(type=\"pil\", height=128, width=128),\n",
        "    outputs = \"text\",\n",
        "    title=\"Gunting Batu Kertas\",\n",
        "    description=\"Upload gambar tangan anda membentuk gunting batu kertas\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "xfvmnqiklGhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "_acPRU6a1Dc3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}